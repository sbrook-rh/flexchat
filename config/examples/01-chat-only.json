{
  "comment": "Minimal config for testing Phase 3 & 4 implementation",
  "llms": {
    "local": {
      "base_url": "http://localhost:11434",
      "provider": "ollama"
    }
  },
  "responses": [
    {
      "comment": "Fallback response - no RAG, just chat",
      "prompt": "You are a helpful AI assistant. Answer the user's question clearly and concisely.\n\nUser question: {{user_message}}",
      "llm": "local",
      "model": "qwen2.5:7b-instruct",
      "max_tokens": 500
    }
  ]
}

